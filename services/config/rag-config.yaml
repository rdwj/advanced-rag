# RAG Pipeline Configuration
# =============================================================================
# This file configures embedding and reranking providers for the pipeline.
#
# IMPORTANT: Before deploying, update the base_url values to match your
# OpenShift cluster's routes. The default configuration uses self-hosted
# Caikit models on OpenShift (caikit-granite for embeddings, caikit-reranker
# for reranking).
#
# Provider Selection:
#   Set 'active' under embedding/rerank to choose the provider.
#   Environment variables can override: RAG_EMBEDDING_PROVIDER, RAG_RERANK_PROVIDER
#
# API Keys:
#   Keys are read from environment variables specified in api_key_env.
#   Never commit actual API keys to this file.
#
# Updating URLs for Your Cluster:
#   Replace the cluster-specific URLs (e.g., *.apps.cluster-mqwwr.mqwwr.sandbox1259.opentlc.com)
#   with your cluster's domain. For example:
#     https://granite-embedding-278m-caikit-embeddings.apps.YOUR-CLUSTER.com
#
# =============================================================================

embedding:
  # Default: Self-hosted Granite embedding model via Caikit
  # Alternatives: openai, openai-large, caikit-minilm, cohere, vllm-local
  active: caikit-granite

  providers:
    # ==========================================================================
    # Self-Hosted Models (Recommended for Production)
    # ==========================================================================

    # Caikit NLP - Granite Embedding (IBM/Red Hat) [DEFAULT]
    # 768 dimensions, good balance of quality and performance
    # Update base_url for your cluster before deployment
    caikit-granite:
      type: caikit
      base_url: https://granite-embedding-278m-caikit-embeddings.apps.cluster-tw52m.tw52m.sandbox448.opentlc.com
      model: granite-embedding-278m
      dimensions: 768
      max_batch: 32
      # API: POST /api/v1/task/embedding
      # Body: {"model_id": "granite-embedding-278m", "inputs": "text"}

    # Caikit NLP - MiniLM (smaller, faster)
    # 384 dimensions, good for dev/test or when speed is critical
    # Update base_url for your cluster before deployment
    caikit-minilm:
      type: caikit
      base_url: https://all-minilm-l6-v2-caikit-embeddings.apps.cluster-tw52m.tw52m.sandbox448.opentlc.com
      model: all-minilm-l6-v2
      dimensions: 384
      max_batch: 64
      # API: POST /api/v1/task/embedding
      # Body: {"model_id": "all-minilm-l6-v2", "inputs": "text"}

    # ==========================================================================
    # Cloud API Providers (Requires API Keys)
    # ==========================================================================

    # OpenAI text-embedding-3-small
    openai:
      type: openai-compatible
      base_url: https://api.openai.com/v1
      api_key_env: OPENAI_API_KEY
      model: text-embedding-3-small
      dimensions: 1536
      max_batch: 64
      max_tokens_per_input: 8191

    # OpenAI text-embedding-3-large (higher quality, higher cost)
    openai-large:
      type: openai-compatible
      base_url: https://api.openai.com/v1
      api_key_env: OPENAI_API_KEY
      model: text-embedding-3-large
      dimensions: 3072
      max_batch: 64
      max_tokens_per_input: 8191

    # Cohere embeddings
    cohere:
      type: cohere
      base_url: https://api.cohere.com/v1
      api_key_env: COHERE_API_KEY
      model: embed-english-v3.0
      dimensions: 1024
      input_type: search_document

    # OpenRouter (routes to various providers)
    openrouter:
      type: openai-compatible
      base_url: https://openrouter.ai/api/v1
      api_key_env: OPENROUTER_API_KEY
      model: openai/text-embedding-3-small
      dimensions: 1536

    # ==========================================================================
    # Local Development / Custom Deployments
    # ==========================================================================

    # Local vLLM deployment
    vllm-local:
      type: openai-compatible
      base_url: http://localhost:8000/v1
      api_key_env: VLLM_API_KEY
      model: BAAI/bge-m3
      dimensions: 1024
      max_batch: 32

    # Generic OpenShift deployed embedding model (customize for your deployment)
    openshift-embedding:
      type: openai-compatible
      base_url: http://embedding-model.ai-models.svc.cluster.local:8000/v1
      api_key_env: EMBEDDING_API_KEY
      model: BAAI/bge-large-en-v1.5
      dimensions: 1024
      max_batch: 32

    # Text Embeddings Inference (TEI) on OpenShift
    tei-openshift:
      type: openai-compatible
      base_url: http://tei-service.ai-apps.svc.cluster.local:8080/v1
      api_key_env: TEI_API_KEY
      model: BAAI/bge-large-en-v1.5
      dimensions: 1024
      max_batch: 32

rerank:
  # Default: Self-hosted MS-MARCO reranker via Caikit
  # Alternatives: cohere, cohere-multilingual, jina, none (to disable)
  active: caikit-reranker

  providers:
    # ==========================================================================
    # Self-Hosted Models (Recommended for Production)
    # ==========================================================================

    # Caikit NLP - MS-MARCO Reranker (IBM/Red Hat) [DEFAULT]
    # Cross-encoder reranker, excellent for improving search precision
    # Update base_url for your cluster before deployment
    caikit-reranker:
      type: caikit
      base_url: https://ms-marco-reranker-caikit-embeddings.apps.cluster-tw52m.tw52m.sandbox448.opentlc.com
      model: ms-marco-reranker
      max_documents: 100
      # API: POST /api/v1/task/rerank
      # Body: {"model_id": "ms-marco-reranker", "inputs": {"query": "...", "documents": [{"text": "..."}]}}

    # ==========================================================================
    # Cloud API Providers (Requires API Keys)
    # ==========================================================================

    # Cohere reranker (English)
    cohere:
      type: cohere
      base_url: https://api.cohere.com/v1
      api_key_env: COHERE_API_KEY
      model: rerank-english-v3.0
      max_documents: 1000

    # Cohere reranker (Multilingual)
    cohere-multilingual:
      type: cohere
      base_url: https://api.cohere.com/v1
      api_key_env: COHERE_API_KEY
      model: rerank-multilingual-v3.0
      max_documents: 1000

    # Jina reranker
    jina:
      type: jina
      base_url: https://api.jina.ai/v1
      api_key_env: JINA_API_KEY
      model: jina-reranker-v2-base-multilingual
      max_documents: 1000

    # ==========================================================================
    # Local Development / Custom Deployments
    # ==========================================================================

    # Local vLLM reranker deployment
    vllm-rerank:
      type: openai-compatible
      base_url: http://localhost:8001/v1
      api_key_env: VLLM_RERANK_API_KEY
      model: BAAI/bge-reranker-v2-m3
      max_documents: 100

    # Generic OpenShift deployed rerank model (customize for your deployment)
    openshift-rerank:
      type: openai-compatible
      base_url: http://rerank-model.ai-models.svc.cluster.local:8000/v1
      api_key_env: RERANK_API_KEY
      model: BAAI/bge-reranker-v2-m3
      max_documents: 100

    # Disable reranking (passthrough - returns results unchanged)
    none:
      type: passthrough

# =============================================================================
# Optional: Microservice URLs
# =============================================================================
# If set, embed_texts() and rerank_documents() will call these services first
# before falling back to direct provider calls.
services:
  embedding_service_url: null  # e.g., http://embedding-service:8000
  rerank_service_url: null     # e.g., http://rerank-service:8003
